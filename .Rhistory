return(result.df)
}
df.final = run.over.all.methods(dat.raw = dat.raw,
data.sample.size.percentage = 1,
imp.methods.vector = c("sample","mean","pmm","norm.nob","norm.boot","norm.predict","norm","cart","rf"),
deletion.chance.slope = -1,
deletion.minimum = 0.1,
deletion.maximum = 0.9,
deletion.step = 0.05,
repetitions.per.step = 2,
data.size = 1,
effect.size.metric = "ROM")
df.final = run.over.all.methods(dat.raw = dat.raw,
data.sample.size.percentage = 1,
imp.methods.vector = c("sample","mean","pmm","norm.nob","norm.boot","norm.predict","norm","cart","rf"),
deletion.chance.slope = -1,
deletion.minimum = 0.1,
deletion.maximum = 0.9,
deletion.step = 0.1,
repetitions.per.step = 1,
data.size = 1,
effect.size.metric = "ROM")
write.table(df.final,"C:\\Users\\Agando\\Desktop\\aktuelle Arbeiten\\SESYNC_multiple_imputation\\LUBDES_multiple_imputations\\all_methods_deletion-1_full_data.csv",
sep="\t",quote=F,dec=".",row.names = FALSE)
df.results = read.table("C:\\Users\\Agando\\Desktop\\aktuelle Arbeiten\\SESYNC_multiple_imputation\\LUBDES_multiple_imputations\\all_methods_deletion-1_full_data.csv",
sep="\t",dec=".",header=T)
dat.full = effect.size.calculation.function(data = dat.raw,effect.size.metric = "ROM")
dat.full.rma.results = meta_analysis.function(dat.full)
names(dat.full.rma.results) = c("full_grand_mean","full_grand_mean_lb","full_grand_mean_ub","full_sample_size_for_rma_calc")
df.results = cbind(df.results,dat.full.rma.results)
smooth.ub.and.lb.for.plotting = function(data){
df.smooth.all = data.frame("deletion_method"=NA, "x" = NA,"y" = NA,"ymin" = NA,"ymax" = NA)[0,]
for(impute.method.temp in unique(df.results$imputation_method)){
gg.grand.mean = ggplot(subset(df.results,imputation_method %in% impute.method.temp),aes(deletion_rate,grand_mean)) +
geom_smooth()
gg.grand.mean.lb = ggplot(subset(df.results,imputation_method %in% impute.method.temp),aes(deletion_rate,grand_mean_lb)) +
geom_smooth()
gg.grand.mean.ub = ggplot(subset(df.results,imputation_method %in% impute.method.temp),aes(deletion_rate,grand_mean_ub)) +
geom_smooth()
df.smooth.temp = data.frame("imputation_method" = as.character(impute.method.temp),
"deletion_rate" = ggplot_build(gg.grand.mean)$data[[1]]$x,
"grand_mean" = ggplot_build(gg.grand.mean)$data[[1]]$y,
"grand_mean_lb" = ggplot_build(gg.grand.mean.lb)$data[[1]]$y,
"grand_mean_ub" = ggplot_build(gg.grand.mean.ub)$data[[1]]$y)
df.smooth.all = rbind(df.smooth.all,df.smooth.temp)
}
return(df.smooth.all)
}
plot.smooth.grand.means.function = function(data){
data.smooth = smooth.ub.and.lb.for.plotting(data)
data.smooth$full_grand_mean = df.results$full_grand_mean[1]
data.smooth$full_grand_mean_lb = df.results$full_grand_mean_lb[1]
data.smooth$full_grand_mean_ub = df.results$full_grand_mean_ub[1]
plot=   ggplot(data=data.smooth) +
# model results
geom_ribbon(aes(x=deletion_rate,ymax=grand_mean_ub,ymin=grand_mean_lb),alpha = 0.2) +
geom_line(aes(x=deletion_rate,y=grand_mean),colour="white",size=2) +
geom_line(aes(x=deletion_rate,y=grand_mean),colour="black",size=0.5) +
#true grand mean
geom_line(aes(x=deletion_rate,y=full_grand_mean),colour="black",size=0.8,linetype="dotdash") +
geom_line(aes(x=deletion_rate,y=full_grand_mean_lb),colour="black",size=1,linetype="dotted") +
geom_line(aes(x=deletion_rate,y=full_grand_mean_ub),colour="black",size=1,linetype="dotted") +
#split data
facet_grid(. ~ imputation_method)  +
theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
return(plot)
}
plot.smooth.grand.means.function(df.results)
df.final = run.over.all.methods(dat.raw = dat.raw,
data.sample.size.percentage = 1,
imp.methods.vector = c("sample","mean","pmm","norm.nob","norm.boot","norm.predict","norm","cart","rf"),
deletion.chance.slope = -3,
deletion.minimum = 0.1,
deletion.maximum = 0.9,
deletion.step = 0.1,
repetitions.per.step = 1,
data.size = 1,
effect.size.metric = "ROM")
write.table(df.final,"C:\\Users\\Agando\\Desktop\\aktuelle Arbeiten\\SESYNC_multiple_imputation\\LUBDES_multiple_imputations\\all_methods_deletion-1_full_data.csv",
sep="\t",quote=F,dec=".",row.names = FALSE)
df.results = read.table("C:\\Users\\Agando\\Desktop\\aktuelle Arbeiten\\SESYNC_multiple_imputation\\LUBDES_multiple_imputations\\all_methods_deletion-1_full_data.csv",
sep="\t",dec=".",header=T)
# results from rma. with full data
dat.full = effect.size.calculation.function(data = dat.raw,effect.size.metric = "ROM")
dat.full.rma.results = meta_analysis.function(dat.full)
names(dat.full.rma.results) = c("full_grand_mean","full_grand_mean_lb","full_grand_mean_ub","full_sample_size_for_rma_calc")
#append to df.results
df.results = cbind(df.results,dat.full.rma.results)
plot.smooth.grand.means.function = function(data){
data.smooth = smooth.ub.and.lb.for.plotting(data)
data.smooth$full_grand_mean = df.results$full_grand_mean[1]
data.smooth$full_grand_mean_lb = df.results$full_grand_mean_lb[1]
data.smooth$full_grand_mean_ub = df.results$full_grand_mean_ub[1]
plot=   ggplot(data=data.smooth) +
# model results
geom_ribbon(aes(x=deletion_rate,ymax=grand_mean_ub,ymin=grand_mean_lb),alpha = 0.2) +
geom_line(aes(x=deletion_rate,y=grand_mean),colour="white",size=2) +
geom_line(aes(x=deletion_rate,y=grand_mean),colour="black",size=0.5) +
#true grand mean
geom_line(aes(x=deletion_rate,y=full_grand_mean),colour="black",size=0.8,linetype="dotdash") +
geom_line(aes(x=deletion_rate,y=full_grand_mean_lb),colour="black",size=1,linetype="dotted") +
geom_line(aes(x=deletion_rate,y=full_grand_mean_ub),colour="black",size=1,linetype="dotted") +
#split data
facet_grid(. ~ imputation_method)  +
theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
return(plot)
}
plot.smooth.grand.means.function(df.results)
##########################
# all local variables in use - for debug ----
dat.raw = dat.raw
data.sample.size.percentage = 1
imp.methods.vector = c("sample","mean","pmm","norm.nob","norm.boot","norm.predict","norm","cart","rf")
deletion.chance.slope = -2
deletion.minimum = 0.1
deletion.maximum = 0.9
deletion.step = 0.1
repetitions.per.step = 0.1
data.size = 1
effect.size.metric = "ROM"
dat.raw = dat.raw
data.sample.size.percentage = data.sample.size.percentage
imputation.method.temp = method.temp
deletion.minimum = deletion.minimum
deletion.maximum = deletion.maximum
deletion.step = deletion.step
repetitions.per.step = repetitions.per.step
deletion.chance.slope = deletion.chance.slope
effect.size.metric = effect.size.metric
del.rate.temp = 0.5
dat.temp =dat.raw
data.sample.size.percentage = data.sample.size.percentage
del.rate.temp = del.rate.temp
deletion.chance.slope = deletion.chance.slope
imputation.method.temp = imputation.method.temp
effect.size.metric = effect.size.metric
imputation.method.temp = "mean"
imputation.method.temp = imputation.method.temp
dat.temp =dat.raw
dat.temp = create.data.subset.function(dat.temp,data.sample.size.percentage)
del.chance.vector.temp = log(dat.temp$control_mean / dat.temp$treat_mean) - (min(log(dat.temp$control_mean / dat.temp$treat_mean)))
del.chance.vector.temp = del.chance.vector.temp + 0.01
del.chance.vector.temp = del.chance.vector.temp ^ deletion.chance.slope
del.chance.vector.temp = log(dat.temp$treat_mean / dat.temp$tcontrol_mean) - (min(log(dat.temp$treat_mean / dat.temp$control_mean)))
test = del.chance.vector.temp
del.chance.vector.temp = del.chance.vector.temp + 0.01
del.chance.vector.temp = del.chance.vector.temp ^ deletion.chance.slope
plot(del.chance.vector.temp ~ test)
min(test)
test = log(dat.temp$treat_mean / dat.temp$tcontrol_mean)
min(test)
test = (dat.temp$treat_mean / dat.temp$tcontrol_mean)
min
min(test)
mindat.temp$treat_mean
min(dat.temp$treat_mean)
min(dat.temp$control_mean)
0/0
max(dat.temp$treat_mean)
max(dat.temp$control_mean)
a = dat.temp$treat_mean / dat.temp$control_mean
min(a)
max(a)
dat.temp$treat_mean
del.chance.vector.temp = log(dat.temp$treat_mean / dat.temp$control_mean) - (min(log(dat.temp$treat_mean / dat.temp$control_mean)))
del.chance.vector.temp = del.chance.vector.temp + 0.01
del.chance.vector.temp = log(dat.temp$treat_mean / dat.temp$control_mean) - (min(log(dat.temp$treat_mean / dat.temp$control_mean)))
test = del.chance.vector.temp
del.chance.vector.temp = del.chance.vector.temp + 0.01
del.chance.vector.temp = del.chance.vector.temp ^ deletion.chance.slope
plot(del.chance.vector.temp ~ test)
deletion.chance.slope
4^-1
6^-2
8^-2
2^-2
1^-2
0.5^-2
0.1^-2
0.1^-1
deletion.chance.slope = -1
del.chance.vector.temp = log(dat.temp$treat_mean / dat.temp$control_mean) - (min(log(dat.temp$treat_mean / dat.temp$control_mean)))
del.chance.vector.temp = del.chance.vector.temp + 0.01
del.chance.vector.temp = del.chance.vector.temp ^ deletion.chance.slope
plot(del.chance.vector.temp ~ test)
del.chance.vector.temp = log(dat.temp$treat_mean / dat.temp$control_mean) - (min(log(dat.temp$treat_mean / dat.temp$control_mean)))
del.chance.vector.temp = del.chance.vector.temp + 0.01
del.chance.vector.temp = del.chance.vector.temp ^ -0.5
plot(del.chance.vector.temp ~ test)
del.chance.vector.temp = log(dat.temp$treat_mean / dat.temp$control_mean) - (min(log(dat.temp$treat_mean / dat.temp$control_mean)))
del.chance.vector.temp = del.chance.vector.temp + 0.01
del.chance.vector.temp = del.chance.vector.temp ^ -0.2
plot(del.chance.vector.temp ~ test)
del.chance.vector.temp = log(dat.temp$treat_mean / dat.temp$control_mean) - (min(log(dat.temp$treat_mean / dat.temp$control_mean)))
del.chance.vector.temp = del.chance.vector.temp + 0.01
del.chance.vector.temp = del.chance.vector.temp ^ -0.1
plot(del.chance.vector.temp ~ test)
del.chance.vector.temp = log(dat.temp$treat_mean / dat.temp$control_mean) - (min(log(dat.temp$treat_mean / dat.temp$control_mean)))
#there are zero log RR which cause problems in the next step
del.chance.vector.temp = del.chance.vector.temp + 0.01
del.chance.vector.temp = del.chance.vector.temp ^ -0.01
plot(del.chance.vector.temp ~ test)
del.chance.vector.temp = log(dat.temp$treat_mean / dat.temp$control_mean) - (min(log(dat.temp$treat_mean / dat.temp$control_mean)))
#there are zero log RR which cause problems in the next step
del.chance.vector.temp = del.chance.vector.temp + 0.01
del.chance.vector.temp = del.chance.vector.temp ^ -0.0001
plot(del.chance.vector.temp ~ test)
del.chance.vector.temp = log(dat.temp$treat_mean / dat.temp$control_mean) - (min(log(dat.temp$treat_mean / dat.temp$control_mean)))
#there are zero log RR which cause problems in the next step
del.chance.vector.temp = del.chance.vector.temp + 0.01
del.chance.vector.temp = del.chance.vector.temp ^ -0.1
plot(del.chance.vector.temp ~ test)
del.chance.vector.temp = log(dat.temp$treat_mean / dat.temp$control_mean) - (min(log(dat.temp$treat_mean / dat.temp$control_mean)))
#there are zero log RR which cause problems in the next step
del.chance.vector.temp = del.chance.vector.temp + 0.01
del.chance.vector.temp = del.chance.vector.temp ^ -1
plot(del.chance.vector.temp ~ test)
dat.temp = dat.temp[order(dat.temp$treat_mean / dat.temp$control_mean),]
dat.temp = dat.temp[order(dat.temp$treat_mean / dat.temp$control_mean,decreasing=F),]
dat.temp$treat_mean / dat.temp$control_mean
1- (dat.temp$treat_mean / dat.temp$control_mean)^2
sqrt(1- (dat.temp$treat_mean / dat.temp$control_mean)^2
sqrt(1- (dat.temp$treat_mean / dat.temp$control_mean)^2)
log(dat.temp$treat_mean / dat.temp$control_mean)
sqrt(log(dat.temp$treat_mean / dat.temp$control_mean)^2)
dat.temp = dat.temp[order(sqrt(log(dat.temp$treat_mean / dat.temp$control_mean)^2),decreasing=F),]
sqrt(log(dat.temp$treat_mean / dat.temp$control_mean)^2)
del.chance.vector.temp = seq(1:nrow(dat.temp)*0.1
del.chance.vector.temp = seq(1:nrow(dat.temp))*0.1
del.chance.vector.temp
del.chance.vector.temp = sqrt(seq(1:nrow(dat.temp)))
del.chance.vector.temp
del.chance.vector.temp = del.chance.vector.temp ^ -1
del.chance.vector.temp
del.chance.vector.temp = sqrt(seq(1:nrow(dat.temp)))
del.chance.vector.temp = del.chance.vector.temp ^ -2
del.chance.vector.temp
1 / 0.002
dat.vector = dat.temp$treat_sd
deletion.rate = del.rate.temp
deletion.chance.vector = del.chance.vector.temp
round(length(dat.vector) * deletion.rate)
length(dat.vector)
seq(1:length(dat.vector))
dat.to.delete = sample(seq(1:length(dat.vector)), size= round(length(dat.vector) * deletion.rate), prob=deletion.chance.vector)
dat.to.delete
sort(dat.to.delete)
hist(dat.to.delete)
# libraries --------------------------------
library(mice)
#library(mi)
#library(Amelia)
#library(mitools)
#library(pan)
library(ggplot2)
library(metafor)
library(ROCR)
library(data.table)
library(plyr)
#############################################
# read data ---------------------------------
dat.raw = read.csv("C:\\Users\\Agando\\Desktop\\aktuelle Arbeiten\\SESYNC_multiple_imputation\\LUBDES_multiple_imputations\\MA_Gerstner2014_complete_observations.csv",
header=T)
dat.raw = dat.raw[,-1]
str(dat.raw)
names(dat.raw) = c("reference","biodiv_aspect","control_n","treat_n","control_mean","treat_mean","control_sd","treat_sd")
#############################################
# cleaning and standard error calculation
dat.raw = dat.raw[-419,] # clear outlier
dat.raw = dat.raw[- which(duplicated(dat.raw)),]
dat.raw$control_se = dat.raw$control_sd / sqrt(dat.raw$control_n)
dat.raw$treat_se = dat.raw$treat_sd / sqrt(dat.raw$treat_n)
#############################################
# functions ---------------------------------
create.data.subset.function = function(data,data.sample.size.percentage){
data.sample.rows = sample(c(1:nrow(data)),nrow(data) * data.sample.size.percentage)
return(data[data.sample.rows,])
}
delete.function = function(dat.vector,deletion.rate,deletion.chance.vector){
dat.to.delete = sample(seq(1:length(dat.vector)), size= round(length(dat.vector) * deletion.rate), prob=deletion.chance.vector)
dat.vector[dat.to.delete] = NA
return(dat.vector)
}
impute.function =function(data.with.missing,column.name.with.missing.values,imputation.method){
if(!(imputation.method %in% "na.omit")){
data.complete = complete(mice(data.with.missing,method = imputation.method,
m=5, maxit =20, printFlag = FALSE))$treat_sd
}else{
data.complete = data.with.missing$treat_sd}
return(data.complete)
}
effect.size.calculation.function = function(data, effect.size.metric){
effect.sizes = escalc(measure = effect.size.metric, data= data, append = FALSE,
m1i = treat_mean, n1i = treat_n, sd1i = treat_sd, m2i = control_mean, n2i = control_n, sd2i = control_sd)
return(effect.sizes)
}
meta_analysis.function = function(data){
rma.temp = rma.uni(yi=data$yi,vi=data$vi,method="REML")
rma.temp.results = data.frame("grand_mean" = rma.temp$b[1],
"grand_mean_lb" = rma.temp$ci.lb[1],
"grand_mean_ub" = rma.temp$ci.ub[1],
"sample_size_for_rma_calc" = rma.temp$k[1])
return(rma.temp.results)
}
one.run.of.grand.mean.calculation.function = function(dat.temp, data.sample.size.percentage, del.rate.temp,
deletion.chance.slope,imputation.method.temp,effect.size.metric){
dat.temp =dat.raw
dat.temp = create.data.subset.function(dat.temp,data.sample.size.percentage)
dat.temp = dat.temp[order(sqrt(log(dat.temp$treat_mean / dat.temp$control_mean)^2),decreasing=F),]
# build vector with chances of deletion based on log response ratio:
# zero - same chance for every study case
# > 1 - higher deletion 10^-1change for large RR
# >-1 - higher deletion chance for low RR
del.chance.vector.temp = sqrt(seq(1:nrow(dat.temp)))
del.chance.vector.temp = del.chance.vector.temp ^ deletion.chance.slope
dat.temp$treat_sd = delete.function(dat.vector = dat.temp$treat_sd,
deletion.rate = del.rate.temp,
deletion.chance.vector = del.chance.vector.temp)
treat_sd.temp = tryCatch({
impute.function(data.with.missing = dat.temp[,c("biodiv_aspect","treat_mean","treat_sd","treat_n")],
column.name.with.missing.values = "treat_sd",
imputation.method = imputation.method.temp)
},error = function(e){
return(NA)
})
if(length(treat_sd.temp) == 1){
dat.temp$treat_sd = NA
}else{
dat.temp$treat_sd = treat_sd.temp
}
dat.temp = dat.temp[which(dat.temp$treat_sd >= 0),]
effect.sizes.temp = tryCatch({
effect.size.calculation.function(data = dat.temp,effect.size.metric = effect.size.metric)
}, error = function(e){
return(NA)
})
if(length(effect.sizes.temp) == 1){
effect.sizes.temp = data.frame("vi"=rep(NA, nrow(dat.temp)),"yi"=rep(NA, nrow(dat.temp)))}
#effect.sizes.temp = effect.sizes.temp[which(!(effect.sizes.temp$vi == 0)),] # probably not neccessary
data.missing.rma.results = tryCatch({
meta_analysis.function(effect.sizes.temp)
}, error = function(e){
return(NA)
})
if(length(data.missing.rma.results) == 1){
data.missing.rma.results =  data.frame("grand_mean" = NA,
"grand_mean_lb" = NA,
"grand_mean_ub" = NA,
"sample_size_for_rma_calc" = NA)}
data.size.temp <<- nrow(dat.temp)
return(data.missing.rma.results)
}
one.complete.imp.method.run = function(dat.raw,data.sample.size.percentage, imputation.method.temp,
deletion.chance.slope, deletion.minimum, deletion.maximum,
deletion.step, repetitions.per.step,effect.size.metric){
del.rate.vector = sort(rep(seq(from = deletion.minimum,to=deletion.maximum,by = deletion.step),repetitions.per.step))
result.df.one.imp.method = data.frame("deletion_rate"= NA,
"grand_mean"= NA,
"grand_mean_lb"= NA,
"grand_mean_ub"= NA,
"sample_size_for_rma_calc"=NA)[0,]
for(del.rate.temp in del.rate.vector){
result.one.run =  one.run.of.grand.mean.calculation.function(
dat.temp =dat.raw,
data.sample.size.percentage = data.sample.size.percentage,
del.rate.temp = del.rate.temp,
deletion.chance.slope = deletion.chance.slope,
imputation.method.temp = imputation.method.temp,
effect.size.metric = effect.size.metric)
result.df.one.run = data.frame("deletion_rate"= del.rate.temp,
"grand_mean"= result.one.run$grand_mean,
"grand_mean_lb"= result.one.run$grand_mean_lb,
"grand_mean_ub"= result.one.run$grand_mean_ub,
"sample_size_for_rma_calc"=result.one.run$sample_size_for_rma_calc)
result.df.one.imp.method = rbind(result.df.one.imp.method,result.df.one.run)
print(paste(del.rate.temp,imputation.method.temp,collapse="-"))
}
return(result.df.one.imp.method)
}
run.over.all.methods = function(dat.raw , data.sample.size.percentage, imp.methods.vector,
deletion.chance.slope, deletion.minimum, deletion.maximum,
deletion.step, repetitions.per.step, data.size,effect.size.metric){
result.df = data.frame("imputation_method"=NA,"data_size"=NA,"deletion_rate"=NA,"effect_size"=NA,
"grand_mean"=NA,"grand_mean_lb"=NA,"grand_mean_ub"=NA,"sample_size_for_rma_calc"=NA)[0,]
for(method.temp in imp.methods.vector){
result.df.one.imp.method = one.complete.imp.method.run(dat.raw = dat.raw,
data.sample.size.percentage = data.sample.size.percentage,
imputation.method.temp = method.temp,
deletion.minimum = deletion.minimum,
deletion.maximum = deletion.maximum,
deletion.step = deletion.step,
repetitions.per.step = repetitions.per.step,
deletion.chance.slope = deletion.chance.slope,
effect.size.metric = effect.size.metric)
result.df.one.imp.method$imputation_method = method.temp
result.df.one.imp.method$data_size = data.sample.size.percentage
result.df.one.imp.method$effect_size = effect.size.metric
result.df = rbind(result.df, result.df.one.imp.method)
}
return(result.df)
}
df.final = run.over.all.methods(dat.raw = dat.raw,
data.sample.size.percentage = 1,
imp.methods.vector = c("sample","mean","pmm","norm.nob","norm.boot","norm.predict","norm","cart","rf"),
deletion.chance.slope = -3,
deletion.minimum = 0.1,
deletion.maximum = 0.9,
deletion.step = 0.1,
repetitions.per.step = 1,
data.size = 1,
effect.size.metric = "ROM")
write.table(df.final,"C:\\Users\\Agando\\Desktop\\aktuelle Arbeiten\\SESYNC_multiple_imputation\\LUBDES_multiple_imputations\\all_methods_deletion-1_full_data.csv",
sep="\t",quote=F,dec=".",row.names = FALSE)
df.results = read.table("C:\\Users\\Agando\\Desktop\\aktuelle Arbeiten\\SESYNC_multiple_imputation\\LUBDES_multiple_imputations\\all_methods_deletion-1_full_data.csv",
sep="\t",dec=".",header=T)
# results from rma. with full data
dat.full = effect.size.calculation.function(data = dat.raw,effect.size.metric = "ROM")
dat.full.rma.results = meta_analysis.function(dat.full)
names(dat.full.rma.results) = c("full_grand_mean","full_grand_mean_lb","full_grand_mean_ub","full_sample_size_for_rma_calc")
#append to df.results
df.results = cbind(df.results,dat.full.rma.results)
smooth.ub.and.lb.for.plotting = function(data){
df.smooth.all = data.frame("deletion_method"=NA, "x" = NA,"y" = NA,"ymin" = NA,"ymax" = NA)[0,]
for(impute.method.temp in unique(df.results$imputation_method)){
gg.grand.mean = ggplot(subset(df.results,imputation_method %in% impute.method.temp),aes(deletion_rate,grand_mean)) +
geom_smooth()
gg.grand.mean.lb = ggplot(subset(df.results,imputation_method %in% impute.method.temp),aes(deletion_rate,grand_mean_lb)) +
geom_smooth()
gg.grand.mean.ub = ggplot(subset(df.results,imputation_method %in% impute.method.temp),aes(deletion_rate,grand_mean_ub)) +
geom_smooth()
df.smooth.temp = data.frame("imputation_method" = as.character(impute.method.temp),
"deletion_rate" = ggplot_build(gg.grand.mean)$data[[1]]$x,
"grand_mean" = ggplot_build(gg.grand.mean)$data[[1]]$y,
"grand_mean_lb" = ggplot_build(gg.grand.mean.lb)$data[[1]]$y,
"grand_mean_ub" = ggplot_build(gg.grand.mean.ub)$data[[1]]$y)
df.smooth.all = rbind(df.smooth.all,df.smooth.temp)
}
return(df.smooth.all)
}
plot.smooth.grand.means.function = function(data){
data.smooth = smooth.ub.and.lb.for.plotting(data)
data.smooth$full_grand_mean = df.results$full_grand_mean[1]
data.smooth$full_grand_mean_lb = df.results$full_grand_mean_lb[1]
data.smooth$full_grand_mean_ub = df.results$full_grand_mean_ub[1]
plot=   ggplot(data=data.smooth) +
# model results
geom_ribbon(aes(x=deletion_rate,ymax=grand_mean_ub,ymin=grand_mean_lb),alpha = 0.2) +
geom_line(aes(x=deletion_rate,y=grand_mean),colour="white",size=2) +
geom_line(aes(x=deletion_rate,y=grand_mean),colour="black",size=0.5) +
#true grand mean
geom_line(aes(x=deletion_rate,y=full_grand_mean),colour="black",size=0.8,linetype="dotdash") +
geom_line(aes(x=deletion_rate,y=full_grand_mean_lb),colour="black",size=1,linetype="dotted") +
geom_line(aes(x=deletion_rate,y=full_grand_mean_ub),colour="black",size=1,linetype="dotted") +
#split data
facet_grid(. ~ imputation_method)  +
theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
return(plot)
}
plot.smooth.grand.means.function(df.results)
df.final = run.over.all.methods(dat.raw = dat.raw,
data.sample.size.percentage = 1,
imp.methods.vector = c("sample","mean","na.omit"),
deletion.chance.slope = -2,
deletion.minimum = 0.1,
deletion.maximum = 0.9,
deletion.step = 0.1,
repetitions.per.step = 1,
data.size = 1,
effect.size.metric = "ROM")
write.table(df.final,"C:\\Users\\Agando\\Desktop\\aktuelle Arbeiten\\SESYNC_multiple_imputation\\LUBDES_multiple_imputations\\all_methods_deletion-1_full_data.csv",
sep="\t",quote=F,dec=".",row.names = FALSE)
df.results = read.table("C:\\Users\\Agando\\Desktop\\aktuelle Arbeiten\\SESYNC_multiple_imputation\\LUBDES_multiple_imputations\\all_methods_deletion-1_full_data.csv",
sep="\t",dec=".",header=T)
dat.full = effect.size.calculation.function(data = dat.raw,effect.size.metric = "ROM")
dat.full.rma.results = meta_analysis.function(dat.full)
names(dat.full.rma.results) = c("full_grand_mean","full_grand_mean_lb","full_grand_mean_ub","full_sample_size_for_rma_calc")
#append to df.results
df.results = cbind(df.results,dat.full.rma.results)
##################################################
# plotting ---------------------------------------
plot.smooth.grand.means.function(df.results)
df.final = run.over.all.methods(dat.raw = dat.raw,
data.sample.size.percentage = 1,
imp.methods.vector = c("sample","mean","na.omit"),
deletion.chance.slope = -2,
deletion.minimum = 0.1,
deletion.maximum = 0.9,
deletion.step = 0.05,
repetitions.per.step = 2,
data.size = 1,
effect.size.metric = "ROM")
write.table(df.final,"C:\\Users\\Agando\\Desktop\\aktuelle Arbeiten\\SESYNC_multiple_imputation\\LUBDES_multiple_imputations\\all_methods_deletion-1_full_data.csv",
sep="\t",quote=F,dec=".",row.names = FALSE)
df.results = read.table("C:\\Users\\Agando\\Desktop\\aktuelle Arbeiten\\SESYNC_multiple_imputation\\LUBDES_multiple_imputations\\all_methods_deletion-1_full_data.csv",
sep="\t",dec=".",header=T)
# results from rma. with full data
dat.full = effect.size.calculation.function(data = dat.raw,effect.size.metric = "ROM")
dat.full.rma.results = meta_analysis.function(dat.full)
names(dat.full.rma.results) = c("full_grand_mean","full_grand_mean_lb","full_grand_mean_ub","full_sample_size_for_rma_calc")
#append to df.results
df.results = cbind(df.results,dat.full.rma.results)
plot.smooth.grand.means.function(df.results)
df.final = run.over.all.methods(dat.raw = dat.raw,
data.sample.size.percentage = 1,
imp.methods.vector = c("sample","mean","pmm","norm.nob","norm.boot","norm.predict","norm","cart","rf"),
deletion.chance.slope = 0,
deletion.minimum = 0.02,
deletion.maximum = 0.98,
deletion.step = 0.01,
repetitions.per.step = 2,
data.size = 1,
effect.size.metric = "ROM")
